{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI E-109a Final Project\n",
    "\n",
    "## Team Members: Melissa Curran, Alexander Dubitskiy, Deepika Sinha, Liangliang Zhang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Introduction\n",
    "\n",
    "The global economy is a very complex system. The stock market is an integral part of the global economy due to its high returns. The stock market is highly correlated to an extent that any fluctuation in this market influences individual and corporate finances that drives the economic health of a country. Stock price forecasting is a popular and important topic in financial and Academic studies; it is marked more by its failure than by its successes since stock prices reflect the judgments and expectations of investors, based on the information available. There is so much uncertainty in the market predictability so that no one can predict where the market will be at the end of the week. Under favorable conditions, the price moves upward so quickly that the investor has little or no time to act upon it. The multiple model building in the prediction of stock prices efforts has shown that the market fluctuations are essentially unpredictable. Time series analysis is the most common and fundamental method used to perform this task. The daily behavior of the market prices reveals that the future stock prices cannot be predicted based on past movements. In this study, we analyzed the behavior of Microsoft stock market prices. We are developing a method of detecting anomalies in non-labeled time series data with adjustable confidence and sensitivity. We will be applying this to the adjusted closing price of Microsoft stock. Overall, the stock price of Microsoft is found to follow the martingale.\n",
    "\n",
    "If the time series of a stock price follows a martingale, then its return is purely non-predictable and investors are unable to make abnormal returns consistently over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### What is an Anomaly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/outlaw.png \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An anomaly is defined as something that deviates from what is standard, normal, or expected.\n",
    "\n",
    "#### Anomalies Versus Outliers\n",
    "\n",
    "An outlier is a legitimate data point originated from a real observation whereas an anomaly is illegitimate and produce by an artificial process. In data mining, anomaly is the set of data points that are considerably different than the remainder of the data. Anomaly detection is the identification of data points, items, observations or events that do not conform to the expected pattern of a given group. Anomaly detection is also known as outlier detection. Anomaly detection is a form of classification.\n",
    "\n",
    "#### Why it is Interesting to Detect Anomalies (Something We Do Not Know Happened)\n",
    "\n",
    "It is interesting to identify unusual or suspicious cases based on deviation from the norm within data that is seemingly homogeneous or follow a pattern.\n",
    "\n",
    "Anomaly detection is an important tool:\n",
    "\n",
    "- in data exploration\n",
    "- and unsupervised learning\n",
    "\n",
    "These anomalies though infrequent may signify a large and significant threat such as cyber intrusions or fraud.\n",
    "\n",
    "#### Attempt to Detect Outliers in MSFT, Problems with this Approach\n",
    "\n",
    "?????\n",
    "\n",
    "#### Why We Need Multidimensional Data\n",
    "\n",
    "An anomaly may be triggered due to one unusual value in a dimension, or a combination of multiple dimensions falling out of bounds. Anomaly detection in a time-series data poses computational challenges, especially for high-dimensional, large data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review of Methods of Anomaly Detection in Time Series Data\n",
    "\n",
    "Existing anomaly detection methods for stock market data can be classified based on how they transform the data prior to anomaly detection and their process of identifying anomalies. (Summary below adapted from Golmohammadi 2015)\n",
    "\n",
    "**Transformations:** Before anomaly detection begins, data must be transformed in order to handle high dimensionality, scaling, and noise and to achieve computational efficiency. This can be done in three ways: aggregation, discretization, and signal processing.\n",
    "\n",
    "- **_Aggregation_** involves dimensionality reduction by aggregating consecutive values, typically by representing them by their average.\n",
    "\n",
    "- **_Discretization_** involves converting the time series into a discrete sequence of finite alphabets, which allows you to use existing symbolic sequence anomaly detection algorithms and also to improve computational efficiency.\n",
    "\n",
    "- **_Signal processing_** involves mapping the data to a different space in order to make it easier to detect outliers and to reduce dimensionality.\n",
    "\n",
    "**Processes of Identifying Anomalies:** The current processes of identifying anomalies can be categorized into five groups: window based, proximity based, prediction based, hidden markov model (HMM) based, and segmentation based.\n",
    "\n",
    "- **_Window Based:_** The time series is divided into evenly sized windows of subsequences and the distance from that sliding window to the windows in the training database determines the anomaly score. Selection of the optimal window size must be done carefully and take into account the length of the anomalous subsequence. This method can be computationally expensive (O((nl)2)), where n is the number of samples in the training and testing datasets and l is the average length of the time series.\n",
    "\n",
    "- **_Proximity Based:_** This method uses pairwise proximity between the testing and training time series using an appropriate distance/similarity kernel. The similarity measure is then used to measure the distance of every two given sequences. A k-NN or clustering method is used to calculate the anomaly score. A major disadvantage is that this method can identify an anomalous time series, but it cannot pinpoint the exact location of the anomaly. It is also highly sensitive to the similarity measure used.\n",
    "\n",
    "- **_Prediction Based:_** These assume that the normal time series is generated from a statistical process while the anomalies do not fit this process. However, the length of history used for prediction is very influential in locating anomalies. In addition, these methods perform very poorly when the time series was not generated from a statistical process.\n",
    "\n",
    "- **_Hidden Markov Model (HMM) Based:_** In these models, the training dataset is used to build a hidden Markov model (HMM), which is then used to probabilistically assign an anomaly score to a given test time series. However, if the underlying time series is not generated from an HMM, it will perform poorly.\n",
    "\n",
    "- **_Segmentation Based:_** The time series is divided into segments. These methods assume that there is an underlying Finite State Automaton (FSA) that models the normal time series, and anomalies are detected when segments do not fit the FSA. However, the segmentation procedure may obscure anomalies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | Aggregation | Discretization | Signal Processing |\n",
    "|-----------------------|\n",
    "| Window Based | kNN (Chandola 2009), SVM (Ma 2003b), (Golmohammadi 2015) | kNN (Chandola 2009) |  |\n",
    "| Proximity Based | PCAD (Protopapas 2006, Rebbapragada 2009), Martingale (Fedorova 2012, Ho 2010, Vovk 2003) |  |  |\n",
    "| Prediction Based | Moving Average (Chatfield 2004), Auto Regression (Chatfield 2004), Kalman Filters (Knorn 2008), SVM (Ma 2003a) | FSA (Michael 2000) | Wavelet (Lotze 2006, Zhang 2003) |\n",
    "| HMM Based | (Liu 2008) | (Qiao 2002), (Zhang 2003) |  |\n",
    "| Segmentation | (Chan 2005), (Mahoney 2005), (Salvador 2005) |  |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### What is a Martingale?\n",
    "\n",
    "<img src=\"images/chimp.png\", width=274, height=265>\n",
    "\n",
    "A martingale is defined as any of several systems of betting in which a player increases the stake usually by doubling each time a bet is lost (reference https://www.system-martingale.com/).\n",
    "\n",
    "#### History of the term\n",
    "1.\tThe concept of martingale in probability theory was introduced by Paul Pierre Levy (1935),\n",
    "2.\tMuch of the original development of the theory was done by Doob (1949, Application of the theory of martingales; 1953, Stochastic Process).\n",
    "3.\tPart of the motivation for works on Martingale was to show the impossibility of successful betting strategies.\n",
    "\n",
    "#### Why it represents confidence\n",
    "\n",
    "?????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Our Method\n",
    "\n",
    "In this project we apply the idea of testing exchangeability online (Vovk et al., 2003) using a martingale framework to detect concept changes in time-varying data streams.\n",
    "\n",
    "In brief, the anomaly detection happens by performing the following steps:\n",
    "\n",
    "1. A data point from the incoming stream is observed.\n",
    "2. A strangeness measure is calculated.\n",
    "3. A p-value is calculated (H0 is no concept change).\n",
    "4. A randomized power martingale is constructed.\n",
    "5. A test is performed using the martingale value.\n",
    "\n",
    "#### Strangeness\n",
    "\n",
    "We wanted our strangeness measure to: \n",
    "\n",
    "-\tbe able to handle multi-dimensional time series  \n",
    "-\tbe able to handle unlabeled data\n",
    "-\tbe simple and flexible \n",
    "\n",
    "We decided to implement two methods, both based on the well-known k-nearest neighbors algorithm:\n",
    "\n",
    "1. Proximity based - maximum distance in the neighborhood.\n",
    "2. Density based - relative density in the neighborhood.\n",
    "\n",
    "The maximum distance in the neighborhood measure is straightforward: given a point and a neighborhood of size k, we find a distance to the furthest point away in the neighborhood.\n",
    "\n",
    "The relative density is a bit more involved. Given a neighborhood of size k, we measure density as an inverse of the sum of all distances between the point and its neighbors. The relative density is calculated by dividing the point density by sum of densities for all the k-nearest neighbors.\n",
    "\n",
    "#### P-Values\n",
    "\n",
    "is calculated as:\n",
    "\n",
    "$$p = \\frac{ count(i:a_{i} > a_{n}) + \\theta*count(i:a_{i} = a_{n}) }{n}$$\n",
    "\n",
    "where $a_{i}$ is the strangeness measure for $i-th$ observation and $\\theta$ is randomly chosen from $[0, 1]$\n",
    "\n",
    "#### Martingale\n",
    "\n",
    "is calculated as:\n",
    "\n",
    "$$M_{n} = \\epsilon p_{n}^{(\\epsilon - 1)} M_{n - 1}$$\n",
    "\n",
    "where $\\epsilon$ is a float value from $[0, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### How We Calculate Strangeness\n",
    "\n",
    "#### Strangeness Measure by the Metrics\n",
    "\n",
    "Our strangeness measures can use the following distance metrics:  \n",
    "\n",
    "- 'euclidean' EuclideanDistance:  $sqrt(sum((x - y)^2))$\n",
    "- 'manhattan' ManhattanDistance:  $sum(|x - y|)$\n",
    "- 'chebyshev' ChebyshevDistance   $max(|x - y|)$\n",
    "\n",
    "In our experiment, it is not so obvious which distance should be used and why, but when we work with high dimensional data, we should try all of them.\n",
    "\n",
    "#### KNN-based, density, proximity\n",
    "\n",
    "With n_neighbors = 1, the relative density measure would not be able to detect observations slowly moving away from the cluster. It looks like we should use a 'conventional' value for n_neighbors (between 3 or 5 in most cases).\n",
    "\n",
    "The proximity measure did well in this scenario with all of the neighborhood sizes. It also looks like larger neighborhood sizes allow the measure to stay 'strange' for longer time periods (that is why it did well here).\n",
    "\n",
    "Again, the separate cluster forming was easily detected by both measures. The relative density appears a bit more stable and tolerant to initial cluster building, but the proximity measure could potentially produce large values for longer time periods, which could be beneficial as we would like our martingale to have enough time for confidence building.\n",
    "\n",
    "It is obvious the martingale needs to build a confidence level by receiving quite a few small p-values before the threshold is reached. That might not work very well in conjunction with KNN-based metrics as the strangeness measure might go down as soon as the new neighborhood is built.\n",
    "\n",
    "This experiment highlights a possible weakness in our model: a small neighborhood size could prevent us from detecting underlying changes in the data stream. In this case, as soon as the number of observation in the separate cluster reached the neighborhood size, the relative density went down and the martingale did not have enough time to build the confidence.\n",
    "\n",
    "The proximity strangeness measure seems to be the weaker option. More investigation should be done to understand where it is applicable.\n",
    "\n",
    "#### Epsilon\n",
    "\n",
    "The initial martingale value is $M_{0} = 1.0$ and with every new observation we calculate the martingale value as $M_{n} = \\epsilon p_{n}^{(\\epsilon - 1)} M_{n - 1}$, where $p$ is the p-value.\n",
    "\n",
    "Changing the epsilon value changes how quickly the martingale rises/falls in the presence of very small or large p-values.\n",
    "\n",
    "Let's simulate a stream of p-values perhaps indicating some change in the middle of the stream and observe changes in the martingale value for different epsilon values.\n",
    "\n",
    "From the chart above, we could see that small epsilon values should not be used for stable streams. A martingale calculated with epsilon = 0.15 would need more then 1000 observations with p-values of 0.1 to breach a threshold of 10.\n",
    "\n",
    "On the chart above, we see how the epsilon value plays a role in the martingale calculation. The concept change happens at step five and all the martingales reach maximum value around step 14 (at different levels). If we set the threshold at level 4.0, then a martingale with epsilon = 0.65 would detect the change at step 10 while martingale with epsilon 0.35 would detect the change at step 14. It looks like too small or too big an epsilon value might not be very sensitive to the changes, and the best performing epsilon values in this case are in 0.75 - 0.95 range.\n",
    "\n",
    "#### Default Values\n",
    "\n",
    "- the neighborhood consists of 3 neighbors\n",
    "- density calculated relatively to total density in the neighborhood\n",
    "- euclidean distance is used\n",
    "- epsilon = 0.92\n",
    "\n",
    "#### Examples of behavior\n",
    "\n",
    "?????\n",
    "\n",
    "- our default martingale calculation is not very sensitive to the sharp but short lived changes of the strangeness measure\n",
    "- changes in the neighborhood size might have a lot of influence on the relative density calculation and the martingale value\n",
    "\n",
    "#### Detecting Mutiple Changes\n",
    "\n",
    "Because of the way we calculate the p-values, we will not be able to detect some sequence of the concept changes. For example, if our system changes from state A to state B, we might be able to detect the change. But the change from B back to A will be unnoticeable because the values associated with state A had been observed before. We might be able to solve this problem by introducing some kind of expiration policy on the historical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### How We Calculate p-value\n",
    "\n",
    "- Formula\n",
    "- Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### How We Use Martingales\n",
    "\n",
    "- How we calculate it\n",
    "- Examples of the behavior\n",
    "- Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Method We Developed\n",
    "\n",
    "#### How To Use\n",
    "\n",
    "?????\n",
    "\n",
    "#### Parameters\n",
    "\n",
    "Our class is called KNNAnomalyDetector and it accepts the following parameters:\n",
    "\n",
    "    threshold - float, optional (default value 2.0)\n",
    "        an anomaly is reported when the threshold is breached\n",
    "    epsilon - float, optional (default value 0.92)\n",
    "        Value from 0.0 to 1.0, used in the martingale calculation\n",
    "    n_neighbors - int, optional (default value 3)\n",
    "        The neighborhood size\n",
    "    metric - string, optional (default value 'euclidean')\n",
    "        The distance metric used to calculate the k-neighbors for each sample point\n",
    "    method - string , 'density' or 'proximity,' default value 'density'\n",
    "        Method of calculating the strangeness function. \n",
    "        When 'density' the strangeness is calculated as density around the point \n",
    "        divided by total density around the neighborhood\n",
    "        When 'proximity' the strangeness is calculated as maximum distance in the the neighborhood\n",
    "    anomaly - string , 'level' or 'change,' default value 'level'\n",
    "        Method of using the threshold\n",
    "        When 'level,' the martingale value is compared with the threshold\n",
    "        When 'change,' the change in martingale value is compared with the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Our Dataset\n",
    "\n",
    "All the data has been collected from open and free sources.\n",
    "\n",
    "**Microsoft Stock**\n",
    "We obtained Microsoft adjusted closing price values from Yahoo Finance for every trading day since 1995. In our dataset, it is represented by the variable 'Adj Close.'\n",
    "\n",
    "**S&P500**\n",
    "We obtained S&P500 closing price values from http://www.cboe.com/micro/buywrite/dailypricehistory.xls for every trading day since 1986 (data from Yahoo Finance was only available from 2005). In our dataset, it is represented by the variable 'SP500.'\n",
    "\n",
    "**10-Year Treasury Constant Maturity Rate**\n",
    "The data was obtained from https://fred.stlouisfed.org/series/DGS10 for every trading day since 1989. In our dataset, it is represented by the variable 'DGS10.'\n",
    "\n",
    "**Federal Funds Rate**\n",
    "The data was obtained from https://fred.stlouisfed.org/series/FEDFUNDS for every calendar month since 1954. We adjust the data frequency to trading day by padding it forward. In our dataset, it is represented by the variable 'FEDFUNDS.'\n",
    "\n",
    "**Microsoft Earnings**\n",
    "The data was obtained from https://www.microsoft.com/en-us/Investor/earnings/trended/quarterly-income-statements.aspx in for every quarter from Q3 1995. In our dataset, it is represented by the variables ‘Revenue,’ ‘Gross Margin,’ ‘Operating Income,’ and ‘Diluted EPS.’ We adjust the data frequency to trading day by padding it forward.\n",
    "\n",
    "**Acquisition History**\n",
    "The data was obtained from https://www.microsoft.com/en-us/Investor/acquisition-history.aspx and consists of the press release date and the company name. It was manually copied and converted into CSV format. In our dataset, it is represented by the variable 'Acquisition,' which takes a value of one if a press release happened on each given date and zero otherwise.\n",
    "\n",
    "**Investment History**\n",
    "The data was obtained from https://www.microsoft.com/en-us/Investor/investment-history.aspx and consists of the press release date and the company name. It was manually copied and converted into CSV format. In our dataset it is represented by the variable 'Investment', which takes a value of one if a press release happened on each given date and zero otherwise.\n",
    "\n",
    "**SEC Filings**\n",
    "The SEC filings data was obtained from https://www.microsoft.com/en-us/Investor/sec-filings.aspx. It was manually copied and converted into CSV format. It was available from 1994 and consists of the filing date and the document type. In our dataset, it is represented by a set of dummy variables. The variable name is the document type and the value is one if the document type was filed on the date, zero otherwise.\n",
    "\n",
    "**Data Refresh**\n",
    "Only the adjusted closed price is automatically refreshed and includes the newest data. All other sources have to be manually updated by downloading relevant files from the sources.\n",
    "\n",
    "<img src=\"images/msft_adj_close.png\", width=554, height=419>\n",
    "\n",
    "<img src=\"images/outliers_first_diff.png\", width=554, height=288>\n",
    "\n",
    "<img src=\"images/outliers_second_diff.png\", width=554, height=288>\n",
    "\n",
    "<img src=\"images/one_class_svm.png\", width=554, height=288>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Detecting Anomalies\n",
    "\n",
    "<img src=\"images/gates.png\", width=366, height=206>\n",
    "\n",
    "- Run for 120, 360 days, explain results\n",
    "- Are they really anomalies?\n",
    "- Validation is challenging, trying to find any information proves something changed (news?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Chan, P., & Mahoney, M. (2005). Modeling multiple time series for anomaly detection. Data Mining, Fifth IEEE International Conference on, 8 pp.\n",
    "\n",
    "Chandola, V., Cheboli, D., & Kumar, V. (2009) Detecting anomalies in a time series database. Technical Report, 1-12.\n",
    "\n",
    "Chatfield, C. (2004). The analysis of time series : An introduction (6th ed., Texts in statistical science). Boca Raton, FL: Chapman & Hall/CRC.\n",
    "\n",
    "Fedorova, V., Gammerman, A., Nouretdinov, I., & Vovk, V. (2012). Plug-in martingales for testing exchangeability on-line. Proceedings of the 29th International Conference on Machine Learning, Edinburgh, Scotland, UK.\n",
    "\n",
    "Golmohammadi, K., & Zaiane, O. (2015). Time series contextual anomaly detection for detecting market manipulation in stock market. Data Science and Advanced Analytics (DSAA), 2015. 36678 2015. IEEE International Conference on, 1-10.\n",
    "\n",
    "Ho, S-S., & Wechsler, H. (2010). A Martingale Framework for Detecting Changes in Data Streams by Testing Exchangeability. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 32(12), 2113-2127.\n",
    "\n",
    "Knorn, F., & Leith, D. (2008). Adaptive Kalman Filtering for anomaly detection in software appliances. INFOCOM Workshops 2008, IEEE, 1-6.\n",
    "\n",
    "Liu, Z., Yu, J. X., Chen, L., & Wu, D. (2008). Detection of shape anomalies: A probabilistic approach using hidden Markov Models. 1325-1327.\n",
    "\n",
    "Lotze, T., Shmueli, G., Murphy, S., & Burkom, H. (2006) A wavelet-based anomaly detector for early detection of disease outbreaks. Work. Mach. Learn. Algorithms Surveill. Event Detect. 23rd Intl Conf. Mach. Learn.\n",
    "Ma, Junshui, & Perkins, Simon. (2003a). Online novelty detection on temporal sequences. 613-618.\n",
    "\n",
    "Ma, J., & Perkins, S. (2003b). Time-series novelty detection using one-class support vector machines. Neural Networks, 2003. Proceedings of the International Joint Conference on, 3, 1741-1745.\n",
    "\n",
    "Mahoney, M., & Chan, P. (2005) Trajectory boundary modeling of time series for anomaly detection. KDD Workshop on Data Mining Methods for Anomaly Detection.\n",
    "\n",
    "Michael, C., & Ghosh, A. (2000) Two state-based approaches to program-based anomaly detection. Proceedings 16th Annual Computer Security Applications Conference (ACSAC’00), 21-30.\n",
    "\n",
    "Protopapas, P., Giammarco, J., Faccioli, L., Struble, M., Dave, R., & Alcock, C. (2006). Finding outlier light curves in catalogues of periodic variable stars. Monthly Notices of the Royal Astronomical Society, 369(2), 677-696.\n",
    "\n",
    "Rebbapragada, U., Protopapas, P., Brodley, C., & Alcock, C. (2009) Finding anomalous periodic time series. Machine Learning, 74(3), 281-313.\n",
    "\n",
    "Salvador, S., & Chan, P. (2005). Learning states and rules for detecting anomalies in time series. Applied Intelligence, 23(3), 241-255.\n",
    "\n",
    "Shafer, G., and Vovk, V. (2001) Probability and Finance: It’s only a Game! Wiley-Interscience.\n",
    "\n",
    "Qiao, Xin, Bin, & Qiao, Y. (2002). Anomaly intrusion detection method based on HMM. Electronics Letters, 38(13), 663-664.\n",
    "\n",
    "Vovk, V. (1993) A Logic of Probability, with Application to the Foundations of Statistics, Journal of the Royal Statistical Society, Series B (Methodological), Vol. 55, 2, 317-351.\n",
    "\n",
    "Vovk, V., Shafer, Glenn, & Gammerman, A. (2005). Algorithmic Learning in a Random World.\n",
    "\n",
    "Vovk, V., Nouretdinov, I., Gammerman, A. (2003) Testing exchangeability on-line. Proceedings of the Twentieth International Conference on Machine Learning (ICML-2003), Washington DC.\n",
    "\n",
    "Zhang, X., Fan, P., & Zhu, Z. (2003). A new anomaly detection method based on hierarchical HMM. Parallel and Distributed Computing, Applications and Technologies, 2003. PDCAT'2003. Proceedings of the Fourth International Conference on, 249-252.\n",
    "\n",
    "Zhang, J., Tsui, F., Wagner, M., & Hogan, W. (2003). Detection of outbreaks from time series data using wavelet transform. AMIA Annual Symposium Proceedings. AMIA Symposium, 748-52.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
